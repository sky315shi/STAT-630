q()
lambda <- 5
# Set the parameters
n1 <- 20
n2 <- 50
lambda <- 5
N <- 10^5  # Large number of repetitions
# Initialize a vector to store proportions
proportions1 <- numeric(N)
proportions2 <- numeric(N)
# Simulate and compute Mn for n = 20 and n = 50
for (i in 1:N) {
# Generate n1 exponential random variables
X1 <- rexp(n1, rate = lambda)
# Compute Mn for n1
Mn1 <- mean(X1)
# Generate n2 exponential random variables
X2 <- rexp(n2, rate = lambda)
# Compute Mn for n2
Mn2 <- mean(X2)
# Store proportions within the desired range for both n1 and n2
proportions1[i] <- as.numeric(Mn1 >= 0.19 & Mn1 <= 0.21)
proportions2[i] <- as.numeric(Mn2 >= 0.19 & Mn2 <= 0.21)
}
# Calculate the proportions
prop_between_0.19_and_0.21_n1 <- sum(proportions1) / N
prop_between_0.19_and_0.21_n2 <- sum(proportions2) / N
prop_between_0.19_and_0.21_n1
prop_between_0.19_and_0.21_n2
# Question 6
## (d)
For the exact distribution
posterior_density <- dbeta(theta_values, posterior_a, posterior_b)
# Prior parameters
prior_a <- 2
prior_b <- 2
# Posterior parameters
posterior_a <- 30
posterior_b <- 24
# Range of theta values
theta_values <- seq(0, 1, length.out = 1000)
# Calculate prior and posterior densities
prior_density <- dbeta(theta_values, prior_a, prior_b)
posterior_density <- dbeta(theta_values, posterior_a, posterior_b)
# Plotting
plot(theta_values, prior_density, type = 'l', col = 'blue',
xlab = 'Theta', ylab = 'Probability Density',
main = 'Prior and Posterior Beta Distributions')
lines(theta_values, posterior_density, col = 'red')
legend('topright', legend = c('Prior Beta(2, 2)', 'Posterior Beta(30, 24)'),
col = c('blue', 'red'), lty = 1)
grid()
credible_90 = qbeta(0.05, posterior_a, posterior_b)
credible_95 = qbeta(0.025, posterior_a, posterior_b)
cat("90% Credible Interval:", round(credible_90, 4),
"-", round(1 - credible_90, 4), "\n")
cat("95% Credible Interval:", round(credible_95, 4),
"-", round(1 - credible_95, 4), "\n")
# Given posterior parameters
alpha <- 29
beta <- 23
# Calculate lower and upper quantiles for the 95% credible interval
lower_quantile <- qgamma(0.025, shape = alpha, rate = 1/beta)
upper_quantile <- qgamma(0.975, shape = alpha, rate = 1/beta)
# Display the 95% credible interval
credible_interval <- c(lower_quantile, upper_quantile)
credible_interval
# Function to calculate power for given theta value
calculate_power <- function(theta) {
n <- 300
mu <- n * 0.5
sigma <- sqrt(n * 0.5 * 0.5)
z1 <- (150 - 17 - mu) / sigma
z2 <- (150 + 17 - mu) / sigma
# Calculate the probability for two-tailed test
power <- pnorm(z1, lower.tail = FALSE) + pnorm(z2)
return(power)
}
# Define a range of theta values
theta_values <- seq(0.1, 0.9, by = 0.01)  # Adjust the range and step size as needed
# Calculate power for each theta value
power_values <- sapply(theta_values, calculate_power)
# Plot the power function
plot(theta_values, power_values, type = "l",
xlab = expression(theta), ylab = "Power",
main = "Power Function for |X - 150| > 17 Test")
getwd()
setwd("C:/Users/95223/OneDrive - Texas A&M University/TAMU/STAT 630/R files")
YOUR_POISSON_DATA <- read.csv("poisson_sample.csv")
# Assuming lambda is the sample mean of your Poisson data
lambda <- mean(YOUR_POISSON_DATA)
getwd()
setwd("C:/Users/95223/OneDrive - Texas A&M University/TAMU/STAT 630/R files")
YOUR_POISSON_DATA <- read.csv("poisson_sample.csv")
# Assuming lambda is the sample mean of your Poisson data
lambda <- mean(YOUR_POISSON_DATA)
# Compute the Wald test statistic
wald_statistic <- (lambda - 2) / sqrt(2)
getwd()
setwd("C:/Users/95223/OneDrive - Texas A&M University/TAMU/STAT 630/R files")
YOUR_POISSON_DATA <- read.csv("poisson_sample.csv")
# Assuming lambda is the sample mean of your Poisson data
lambda <- mean(YOUR_POISSON_DATA$T)
# Compute the Wald test statistic
wald_statistic <- (lambda - 2) / sqrt(2)
# Calculate the p-value for the Wald test
wald_p_value <- 2 * pnorm(-abs(wald_statistic))
# Display the results
cat("Wald Test:\n")
cat("Test Statistic:", wald_statistic, "\n")
cat("P-value:", wald_p_value, "\n")
# Function to calculate the score test statistic
calculate_score_statistic <- function(lambda) {
score_statistic <- (lambda - 2) / sqrt(2)
return(score_statistic)
}
# Calculate the score test statistic
score_statistic <- calculate_score_statistic(lambda)
# Calculate the p-value for the Score test
score_p_value <- 2 * pnorm(-abs(score_statistic))
# Display the results
cat("\nScore Test:\n")
cat("Test Statistic:", score_statistic, "\n")
cat("P-value:", score_p_value, "\n")
ore for alpha = 0.01 (two-tailed test)
# Calculate the z-score for alpha = 0.01 (two-tailed test)
alpha <- 0.01
z_score <- qnorm(1 - alpha / 2)
z_score
# Define a range of theta values
theta_values <- seq(0.1, 0.9, by = 0.01)  # Adjust the range and step size as needed
# Function to calculate power for given theta value
calculate_power <- function(theta) {
n <- 300
mu <- n * theta
sigma <- sqrt(n * theta * (1 - theta))
z1 <- (150 - 17 - mu) / sigma
z2 <- (150 + 17 - mu) / sigma
# Calculate the probability for two-tailed test
power <- pnorm(z1, lower.tail = FALSE) + pnorm(z2)
return(power)
}
# Calculate power for each theta value
power_values <- sapply(theta_values, calculate_power)
# Plot the power function
plot(theta_values, power_values, type = "l",
xlab = expression(theta), ylab = "Power",
main = "Power Function for |X - 150| > 17 Test")
